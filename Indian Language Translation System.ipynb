{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install all required Libraries**"
      ],
      "metadata": {
        "id": "3Yc40FJkPiSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice scipy\n",
        "!pip install transformers\n",
        "!pip install librosa\n",
        "!pip install soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlvih_IuQWpR",
        "outputId": "727d2072-79a1-4afb-8561-a9980190e7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.5.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VarunGumma/IndicTransToolkit\n",
        "%cd IndicTransToolkit\n",
        "!pip install --editable ./\n",
        "!pip install indic-nlp-library\n",
        "!pip install gTTS\n",
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "cgVZaequWwLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7b6843-9d75-46a2-d72c-68af6fab3291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IndicTransToolkit'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 155 (delta 34), reused 45 (delta 30), pack-reused 95 (from 1)\u001b[K\n",
            "Receiving objects: 100% (155/155), 3.88 MiB | 5.57 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/IndicTransToolkit\n",
            "Obtaining file:///content/IndicTransToolkit\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library (from IndicTransToolkit==1.0.2)\n",
            "  Cloning https://github.com/VarunGumma/indic_nlp_library to /tmp/pip-install-4kvvmq7m/indic-nlp-library-it2_e5316c52fa224c96a91635912ebd31ca\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library /tmp/pip-install-4kvvmq7m/indic-nlp-library-it2_e5316c52fa224c96a91635912ebd31ca\n",
            "  Resolved https://github.com/VarunGumma/indic_nlp_library to commit 601521e05ed0ed8f2165ac317a47d186e25b6f0d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (75.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (2.5.1+cu121)\n",
            "Collecting sacremoses (from IndicTransToolkit==1.0.2)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from IndicTransToolkit==1.0.2) (4.47.1)\n",
            "Collecting sacrebleu (from IndicTransToolkit==1.0.2)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-argparse (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx_rtd_theme (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.26.4)\n",
            "Collecting portalocker (from sacrebleu->IndicTransToolkit==1.0.2)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->IndicTransToolkit==1.0.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->IndicTransToolkit==1.0.2) (5.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransToolkit==1.0.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransToolkit==1.0.2) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses->IndicTransToolkit==1.0.2) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->IndicTransToolkit==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->IndicTransToolkit==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->IndicTransToolkit==1.0.2) (0.4.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->IndicTransToolkit==1.0.2) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->IndicTransToolkit==1.0.2) (2024.12.14)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx_rtd_theme->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (1.4.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransToolkit==1.0.2) (2.2.1)\n",
            "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: indic-nlp-library-IT2\n",
            "  Building wheel for indic-nlp-library-IT2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for indic-nlp-library-IT2: filename=indic_nlp_library_IT2-0.0.2-py3-none-any.whl size=49560 sha256=800b1b35f984ffb3b4e785a9927ab94eaf117f3a6bc43d0b0d177a2ccb750eed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ong9uuia/wheels/e9/72/fa/bd9f19a3f2bacb50efcaf28b7ab89fe7ca539e35b75334befc\n",
            "Successfully built indic-nlp-library-IT2\n",
            "Installing collected packages: morfessor, sacremoses, portalocker, colorama, sacrebleu, sphinxcontrib-jquery, sphinx-argparse, sphinx_rtd_theme, indic-nlp-library-IT2, IndicTransToolkit\n",
            "  Running setup.py develop for IndicTransToolkit\n",
            "Successfully installed IndicTransToolkit-1.0.2 colorama-0.4.6 indic-nlp-library-IT2-0.0.2 morfessor-2.0.6 portalocker-3.0.0 sacrebleu-2.4.3 sacremoses-0.1.1 sphinx-argparse-0.5.2 sphinx_rtd_theme-3.0.2 sphinxcontrib-jquery-4.1\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (8.1.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.2)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.12.14)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.92\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.12.14)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n",
            "/content/IndicTransToolkit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QlP5fs1UeFL",
        "outputId": "52991762-efee-4829-d386-f384a5cb60ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Speech To Text Class**"
      ],
      "metadata": {
        "id": "P5AyBJPIdW7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeHIa1IBOoBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "\n",
        "\n",
        "class AudioTranscriber:\n",
        "    def __init__(self, model_name=\"openai/whisper-large-v2\", device=None):\n",
        "        \"\"\"\n",
        "        Initialize the AudioTranscriber with specified model.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name or path of the Whisper model to use\n",
        "            device (str): Device to run the model on ('cuda', 'cpu', or None for auto-detection)\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Initialize processor and model\n",
        "        self.processor = None\n",
        "        self.model = None\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the Whisper model and processor.\"\"\"\n",
        "        try:\n",
        "            self.processor = AutoProcessor.from_pretrained(self.model_name)\n",
        "            self.model = AutoModelForSpeechSeq2Seq.from_pretrained(self.model_name)\n",
        "            self.model.to(self.device)\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to load model: {str(e)}\")\n",
        "\n",
        "    def _load_audio(self, file_path, sample_rate=16000):\n",
        "        \"\"\"\n",
        "        Load and preprocess audio file.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the audio file\n",
        "            sample_rate (int): Target sample rate for the audio\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Loaded and resampled audio data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            audio, _ = librosa.load(file_path, sr=sample_rate)\n",
        "            return audio\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to load audio file: {str(e)}\")\n",
        "\n",
        "    def transcribe(self, audio_path, return_timestamps=False):\n",
        "        \"\"\"\n",
        "        Transcribe audio file to text.\n",
        "\n",
        "        Args:\n",
        "            audio_path (str): Path to the audio file\n",
        "            return_timestamps (bool): Whether to return timestamps with the transcription\n",
        "\n",
        "        Returns:\n",
        "            str: Transcribed text\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load and preprocess audio\n",
        "            audio = self._load_audio(audio_path)\n",
        "\n",
        "            # Prepare input features\n",
        "            inputs = self.processor(\n",
        "                audio,\n",
        "                return_tensors=\"pt\",\n",
        "                sampling_rate=16000\n",
        "            ).to(self.device)\n",
        "\n",
        "            # Generate transcription\n",
        "            with torch.no_grad():\n",
        "                if return_timestamps:\n",
        "                    generated = self.model.generate(\n",
        "                        inputs.input_features,\n",
        "                        return_timestamps=True\n",
        "                    )\n",
        "                else:\n",
        "                    generated = self.model.generate(\n",
        "                        inputs.input_features\n",
        "                    )\n",
        "\n",
        "            # Decode the output\n",
        "            transcription = self.processor.batch_decode(\n",
        "                generated,\n",
        "                skip_special_tokens=True\n",
        "            )[0]\n",
        "\n",
        "            return transcription\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Transcription failed: {str(e)}\")\n",
        "\n",
        "    def transcribe_batch(self, audio_paths):\n",
        "        \"\"\"\n",
        "        Transcribe multiple audio files.\n",
        "\n",
        "        Args:\n",
        "            audio_paths (list): List of paths to audio files\n",
        "\n",
        "        Returns:\n",
        "            list: List of transcribed texts\n",
        "        \"\"\"\n",
        "        return [self.transcribe(path) for path in audio_paths]\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Clean up resources when the object is destroyed.\"\"\"\n",
        "        try:\n",
        "            del self.model\n",
        "            del self.processor\n",
        "            torch.cuda.empty_cache()\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using STT Class"
      ],
      "metadata": {
        "id": "6vzcZibaPqbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noxLo0yvidMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcriber = AudioTranscriber()\n",
        "audio_file = (\"/content/Sample02.mp3\")\n",
        "transcription = transcriber.transcribe(audio_file)\n",
        "# transcription, language = transcriber.transcribe(audio_file, return_language=True)\n",
        "print(\"Transcription:\", transcription)\n",
        "sttoutput=[transcription]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "9Yhg7pHfPp1q",
        "outputId": "139f8064-07fc-4171-dae5-e4bb5737c8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to load model: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 5.06 MiB is free. Process 20124 has 14.74 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 430.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-51a2f317003f>\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSpeechSeq2Seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3163\u001b[0m                 )\n\u001b[0;32m-> 3164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 5.06 MiB is free. Process 20124 has 14.74 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 430.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2b66d72dad57>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranscriber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioTranscriber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Sample02.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscriber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# transcription, language = transcriber.transcribe(audio_file, return_language=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transcription:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-51a2f317003f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-51a2f317003f>\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load model: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to load model: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 5.06 MiB is free. Process 20124 has 14.74 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 430.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wDT2y1_GierR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Translation Class**"
      ],
      "metadata": {
        "id": "e3U-sDT0REDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig, AutoTokenizer\n",
        "from IndicTransToolkit.processor import IndicProcessor\n",
        "\n",
        "\n",
        "\n",
        "class IndicTranslator:\n",
        "    def __init__(self, checkpoint_dir=\"ai4bharat/indictrans2-indic-indic-1B\", batch_size=4, quantization=None):\n",
        "        \"\"\"\n",
        "        Initialize the IndicTranslator with model configuration.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_dir (str): Path to the model checkpoint\n",
        "            batch_size (int): Size of batches for translation\n",
        "            quantization (str): Quantization type ('4-bit', '8-bit', or None)\n",
        "        \"\"\"\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.processor = IndicProcessor(inference=True)\n",
        "        self.tokenizer, self.model = self._initialize_model_and_tokenizer(quantization)\n",
        "\n",
        "    def _initialize_model_and_tokenizer(self, quantization):\n",
        "        \"\"\"Initialize and configure the model and tokenizer.\"\"\"\n",
        "        if quantization == \"4-bit\":\n",
        "            qconfig = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "            )\n",
        "        elif quantization == \"8-bit\":\n",
        "            qconfig = BitsAndBytesConfig(\n",
        "                load_in_8bit=True,\n",
        "                bnb_8bit_use_double_quant=True,\n",
        "                bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "            )\n",
        "        else:\n",
        "            qconfig = None\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(self.checkpoint_dir, trust_remote_code=True)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "            self.checkpoint_dir,\n",
        "            trust_remote_code=True,\n",
        "            low_cpu_mem_usage=True,\n",
        "            quantization_config=qconfig,\n",
        "        )\n",
        "\n",
        "        if qconfig is None:\n",
        "            model = model.to(self.device)\n",
        "            if self.device == \"cuda\":\n",
        "                model.half()\n",
        "\n",
        "        model.eval()\n",
        "        return tokenizer, model\n",
        "\n",
        "    def translate(self, texts, source_lang, target_lang):\n",
        "        \"\"\"\n",
        "        Translate a list of texts from source language to target language.\n",
        "\n",
        "        Args:\n",
        "            texts (list): List of input texts to translate\n",
        "            source_lang (str): Source language code (e.g., 'tam_Taml')\n",
        "            target_lang (str): Target language code (e.g., 'hin_Deva')\n",
        "\n",
        "        Returns:\n",
        "            list: List of translated texts\n",
        "        \"\"\"\n",
        "        translations = []\n",
        "        for i in range(0, len(texts), self.batch_size):\n",
        "            batch = texts[i: i + self.batch_size]\n",
        "\n",
        "            # Preprocess the batch\n",
        "            batch = self.processor.preprocess_batch(batch, src_lang=source_lang, tgt_lang=target_lang)\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = self.tokenizer(\n",
        "                batch,\n",
        "                truncation=True,\n",
        "                padding=\"longest\",\n",
        "                return_tensors=\"pt\",\n",
        "                return_attention_mask=True,\n",
        "            ).to(self.device)\n",
        "\n",
        "            # Generate translations\n",
        "            with torch.no_grad():\n",
        "                generated_tokens = self.model.generate(\n",
        "                    **inputs,\n",
        "                    use_cache=True,\n",
        "                    min_length=0,\n",
        "                    max_length=256,\n",
        "                    num_beams=5,\n",
        "                    num_return_sequences=1,\n",
        "                )\n",
        "\n",
        "            # Decode translations\n",
        "            with self.tokenizer.as_target_tokenizer():\n",
        "                generated_tokens = self.tokenizer.batch_decode(\n",
        "                    generated_tokens.detach().cpu().tolist(),\n",
        "                    skip_special_tokens=True,\n",
        "                    clean_up_tokenization_spaces=True,\n",
        "                )\n",
        "\n",
        "            # Postprocess translations\n",
        "            translations.extend(self.processor.postprocess_batch(generated_tokens, lang=target_lang))\n",
        "\n",
        "            del inputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return translations\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Clean up resources when the object is destroyed.\"\"\"\n",
        "        try:\n",
        "            del self.tokenizer\n",
        "            del self.model\n",
        "            torch.cuda.empty_cache()\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "wHoU_owzQUwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using MT Class**"
      ],
      "metadata": {
        "id": "imHmVa82UoWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = IndicTranslator()\n",
        "# texts = ['என் பெயர் விக்னேஷ் நான் பங்க்குலூரில் வசிக்கிறேன்']\n",
        "texts= sttoutput\n",
        "lang_dict = {'Assamese': 'asm_Beng', 'Bengali': 'ben_Beng', 'Bodo': 'brx_Deva', 'Dogri': 'doi_Deva', 'English': 'eng_Latn',\n",
        "             'Konkani': 'gom_Deva', 'Gujarati': 'guj_Gujr', 'Hindi': 'hin_Deva', 'Kannada': 'kan_Knda', 'Kashmiri (Arabic)': 'kas_Arab',\n",
        "             'Kashmiri (Devanagari)': 'kas_Deva', 'Maithili': 'mai_Deva','Telugu': 'tel_Telu','Tamil':'tam_Taml'}\n",
        "source_lang = lang_dict['Kannada']\n",
        "target_lang = lang_dict['Tamil']\n",
        "translations = translator.translate(texts, source_lang, target_lang)\n",
        "print(translations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYTDBozwUkKH",
        "outputId": "c6233b61-1eae-4649-ef1e-cd1a95bb9a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['மருத்துவமனை எங்கே? ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEXT TO SPEECH**"
      ],
      "metadata": {
        "id": "g9-7A-OTVAli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "#translations=\"నా పేరు విఘ్నేష్ నేను బంకులూర్లో నివసిస్తున్నాను. \"\n",
        "# translations=\"என் பெயர் விக்னேஷ் நான் பங்க்குலூரில் வசிக்கிறேன்\"\n",
        "indian_languages = {\n",
        "    'asm_Beng': 'as',    'ben_Beng': 'bn',    'brx_Deva': 'brx',    'doi_Deva': 'doi',    'gom_Deva': 'gom',    'guj_Gujr': 'gu',    'hin_Deva': 'hi',   'kan_Knda': 'kn',    'kas_Arab': 'ks',\n",
        "    'kas_Deva': 'ks',    'mai_Deva': 'mai',    'tel_Telu': 'te',    'tam_Taml': 'ta'}\n",
        "\n",
        "translation = translations[0]\n",
        "language = indian_languages[f'{target_lang}']\n",
        "speech = gTTS(text=translation, lang=language, slow=False)\n",
        "speech.save(f\"output_{language}.mp3\")\n",
        "os.system(\"start output.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y0vPlPyUvwX",
        "outputId": "556bce11-ade1-4cf0-e1b2-a1e977aa1e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32512"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWboHK-ojFE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}